{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SENTIMETER.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNfnmOpPWYJuE5OZmYZFbVs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RonitGandhi/Hacksprint_PS01_InputOutput/blob/model_branch/SENTIMETER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqCVEcz2k1N1",
        "outputId": "0c439251-2e09-4044-b579-088d569518f4"
      },
      "source": [
        "import glob\n",
        "import os\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "import pandas as pd\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from textblob import TextBlob"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1aM_ciml_ug"
      },
      "source": [
        "currency = [\n",
        "    \"BTC\",\n",
        "    \"ETH\",\n",
        "    \"ADA\",\n",
        "    \"BNB\",\n",
        "    \"USDT\",\n",
        "    \"XRP\",\n",
        "    \"SOL\",\n",
        "    \"DOT\",\n",
        "    \"USDC\",\n",
        "    \"DOGE\"\n",
        "]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-61b24xhmBvR"
      },
      "source": [
        "def process_ccy(curr):\n",
        "    pd_df = pd.concat(\n",
        "        [pd.read_csv(f) for f in glob.glob(f\"clean_data/{curr}*.csv\", recursive=True)],\n",
        "        ignore_index=True,\n",
        "    )\n",
        "\n",
        "    print(f\"Number of records loaded for {curr}\", len(pd_df))\n",
        "    pd_df[[\"coin_symbol\", \"tweet_id\", \"created_at\", \"date\", \"hour\"]].to_csv(\n",
        "        f\"clean_data/ccy_tweets/{curr}_tweets.csv\", index=False\n",
        "    )\n",
        "\n",
        "    return pd_df"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wb7VaccemO0v"
      },
      "source": [
        "combined_df = pd.concat(\n",
        "    [process_ccy(c) for c in currency],\n",
        "    ignore_index=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9gH0X_lmPbX"
      },
      "source": [
        "combined_df.sort_values(by=[\"mined_at\"], inplace=True, ignore_index=True)\n",
        "combined_df.drop_duplicates(\n",
        "    subset=[\"tweet_id\"], inplace=True, keep=\"last\", ignore_index=True\n",
        ")\n",
        "combined_df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGT7rwKUmT7G"
      },
      "source": [
        "combined_df.sort_values(by=[\"tweet_id\"], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So7syw3EmUai"
      },
      "source": [
        "len(combined_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aORRhVSmZHt"
      },
      "source": [
        "stop_words = stopwords.words(\"english\")\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "tokenizer = RegexpTokenizer(r\"\\w+\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRr0Ea1dmaDR"
      },
      "source": [
        "def preprocess(text):\n",
        "    words = [lemmatizer.lemmatize(w) for w in text if w not in stop_words]\n",
        "    stem_text = \" \".join([stemmer.stem(i) for i in words])\n",
        "    return stem_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKqdFFrLmc4P"
      },
      "source": [
        "combined_df[\"processed text\"] = combined_df[\"text\"].apply(\n",
        "    lambda x: preprocess(tokenizer.tokenize(x.lower()))\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlSR-CEAmdWW"
      },
      "source": [
        "def getSentiment(tweet):\n",
        "    analysis = TextBlob(tweet)\n",
        "    return analysis.sentiment.polarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRbnWw1gmgfw"
      },
      "source": [
        "combined_df[\"polarity\"] = combined_df[\"processed text\"].apply(lambda x: getSentiment(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzv6lhVzmiT-"
      },
      "source": [
        "combined_df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3jrfpNnmk0L"
      },
      "source": [
        "combined_df[\"sentiment\"] = combined_df[\"polarity\"].apply(\n",
        "    lambda s: \"Postive\" if s > 0 else (\"Neutral\" if s == 0 else \"Negative\")\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAy3UKrLmmuT"
      },
      "source": [
        "combined_df.to_csv(\"full_tweets.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}